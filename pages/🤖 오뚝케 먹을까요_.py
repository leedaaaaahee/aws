import streamlit as st
from streamlit_chat import message

import os
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders.csv_loader import CSVLoader
from langchain.vectorstores import FAISS
from langchain.prompts.prompt import PromptTemplate

# api key
os.environ["OPENAI_API_KEY"] = "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"

loader = CSVLoader(file_path="./data/total.csv", encoding="utf-8")
data = loader.load()

embeddings = OpenAIEmbeddings()
vectors = FAISS.from_documents(data, embeddings)

custom_template = """
ë„ˆëŠ” ë ˆì‹œí”¼ë¥¼ ì°¾ì•„ì£¼ëŠ” AI ë´‡ì´ì•¼.
í–‰ë™ê·œì¹™ì€ ë‹¤ìŒê³¼ ê°™ì•„.
csv íŒŒì¼ì—ì„œ ì‚¬ìš©ìê°€ ë¨¹ê³  ì‹¶ì€ ìŒì‹ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë ˆì‹œí”¼ í•˜ë‚˜ë¥¼ ì°¾ì•„ì„œ ê·¸ ìŒì‹ì˜ ì´ë¦„, ë ˆì‹œí”¼ì¬ë£Œ, ë ˆì‹œí”¼ë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ì¤˜.

- ì´ë¦„ : ì´ë¦„
\n\n
- ì¬ë£Œ : ë ˆì‹œí”¼ì¬ë£Œ
\n\n
- ë ˆì‹œí”¼ : ë ˆì‹œí”¼
"""

CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)

chain = ConversationalRetrievalChain.from_llm(llm = ChatOpenAI(temperature=0.0,model_name='gpt-3.5-turbo-16k'),
                                                                   retriever=vectors.as_retriever(),
                                                                   condense_question_prompt=CUSTOM_QUESTION_PROMPT)

#í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_icon="ğŸ˜—",
    page_title="ì˜¤ëšì¼€ë¨¹ì§€?!ğŸ˜‹",
    layout="wide",
)

## Title
st.image('./pages/img/banner.png', use_column_width = True)
st.header("ğŸ¤– ì˜¤ëšì¼€ ë¨¹ì„ê¹Œìš”?")

def conversational_chat(query):

    result = chain({"question": query, "chat_history": st.session_state['history']})
    st.session_state['history'].append((query, result["answer"]))

    return result["answer"]

if 'history' not in st.session_state:
    st.session_state['history'] = []

if 'generated' not in st.session_state:
    st.session_state['generated'] = ["ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ìŒì‹ì„ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ğŸ¤—"]

if 'past' not in st.session_state:
    st.session_state['past'] = ["ğŸ‘‹"]

response_container = st.container()
container = st.container()

with container:
    with st.form(key='my_form', clear_on_submit=True):

        user_input = st.text_input("Query:", placeholder="[ë©”ë‰´ì´ë¦„] ë ˆì‹œí”¼ ì°¾ì•„ì¤˜.", key='input')
        submit_button = st.form_submit_button(label='Send')

    if submit_button and user_input:
        output = conversational_chat(user_input)

        st.session_state['past'].append(user_input)
        st.session_state['generated'].append(output)

if st.session_state['generated']:
    with response_container:
        for i in range(len(st.session_state['generated'])):
            message(st.session_state["past"][i], is_user=True, key=str(i) + '_user', avatar_style="big-smile")
            message(st.session_state["generated"][i], key=str(i), avatar_style="thumbs")
            if i != 0:
                message("ë‹¤ë¥¸ ìŒì‹ ë ˆì‹œí”¼ë¥¼ ë” ì•Œê³  ì‹¶ìœ¼ì‹œë‹¤ë©´, í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.", avatar_style="thumbs")